# Portainer Environment Variables for GPT Researcher
# Sensitive values should be set in Portainer UI, not in this file

# Ollama Configuration
OPENAI_BASE_URL=http://host.docker.internal:11434/v1
OPENAI_API_KEY=ollama
OLLAMA_BASE_URL=http://host.docker.internal:11434

# LLM Models (optimized for research performance)
FAST_LLM=ollama:qwen2.5vl:latest       # ~3GB - 150 t/s, 128K context
SMART_LLM=ollama:gpt-oss:20b           # ~6.5GB - 140 t/s, 131K context
STRATEGIC_LLM=ollama:qwen3-coder:30b   # ~19GB - 154 t/s, 256K context

# Embedding Model (new format)
EMBEDDING=ollama:snowflake-arctic-embed2
OLLAMA_EMBEDDING_MODEL=snowflake-arctic-embed2
EMBEDDING_PROVIDER=ollama

# Search Configuration (set in Portainer UI)
TAVILY_API_KEY=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

# GPT Researcher Configuration - High Quality Research Settings
MAX_ITERATIONS=3
LOG_LEVEL=INFO
PORT=8000

# Token Limits (optimized for each model's context capabilities)
FAST_TOKEN_LIMIT=8000        # qwen2.5vl: 128K context
SMART_TOKEN_LIMIT=12000      # gpt-oss: 131K context  
STRATEGIC_TOKEN_LIMIT=20000  # qwen3-coder: 256K context
SUMMARY_TOKEN_LIMIT=1000
MAX_SCRAPER_WORKERS=20
MAX_SUBTOPICS=5
TOTAL_WORDS=2500

# Frontend Configuration
NEXT_PUBLIC_GPTR_API_URL=http://gpt-researcher:8000

# Optional API keys (set in Portainer UI if needed)
LANGCHAIN_API_KEY=
ANTHROPIC_API_KEY=